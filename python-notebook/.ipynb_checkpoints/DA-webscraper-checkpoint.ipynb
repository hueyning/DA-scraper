{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Scraping</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.pipelines.images import ImagesPipeline\n",
    "from scrapy.exceptions import DropItem\n",
    "\n",
    "class ImageItem(scrapy.Item):\n",
    "\n",
    "    # for downloading images in ImagePipeline\n",
    "    image_urls = scrapy.Field()\n",
    "    \n",
    "    #image attributes\n",
    "    titles = scrapy.Field()\n",
    "    date_posted = scrapy.Field()\n",
    "    hashtags = scrapy.Field()\n",
    "    \n",
    "    #stats\n",
    "    views = scrapy.Field()\n",
    "    faves = scrapy.Field()\n",
    "    comments = scrapy.Field()\n",
    "    downloads = scrapy.Field()\n",
    "    \n",
    "    #artist details\n",
    "    artists = scrapy.Field()\n",
    "    artist_urls = scrapy.Field()\n",
    "    artist_deviations = scrapy.Field()\n",
    "    artist_comments = scrapy.Field()\n",
    "    artist_page_views = scrapy.Field()\n",
    "    artist_scraps = scrapy.Field()\n",
    "    artist_watchers = scrapy.Field()\n",
    "    artist_critiques = scrapy.Field()\n",
    "    artist_forum_posts = scrapy.Field()\n",
    "    artist_faves = scrapy.Field()\n",
    "    artist_asl = scrapy.Field() #age, sex, location\n",
    "    artist_dob = scrapy.Field() #date of birth\n",
    "    account_age = scrapy.Field() #how old the account is\n",
    "    membership = scrapy.Field() #artist current membership status\n",
    "    \n",
    "    # to be filled in by ImagePipeline\n",
    "    image_paths = scrapy.Field()\n",
    "    images = scrapy.Field()\n",
    "    \n",
    "class MyImagesPipeline(ImagesPipeline):\n",
    "\n",
    "    def get_media_requests(self, item, info):\n",
    "        for image_url in item['image_urls']:\n",
    "            yield scrapy.Request(image_url)\n",
    "\n",
    "    def item_completed(self, results, item, info):\n",
    "        image_paths = [x['path'] for ok, x in results if ok]\n",
    "        if not image_paths:\n",
    "            raise DropItem(\"Item contains no images\")\n",
    "        item['image_paths'] = image_paths\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSpider(scrapy.Spider):\n",
    "    \n",
    "    name = 'images'\n",
    "    \n",
    "    start_urls = ['https://www.deviantart.com/popular-all-time/?q=sherlock&offset=0']\n",
    "    \n",
    "    \n",
    "    #initialize offset at 0\n",
    "    offset = 0\n",
    "    #set offset limit to control the amount of images downloaded\n",
    "    offset_limit = 8000\n",
    "    #count items\n",
    "    old_items = 0\n",
    "    new_items = 0\n",
    "    \n",
    "\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.INFO,\n",
    "        'ITEM_PIPELINES': {'__main__.MyImagesPipeline': 1}, #enable image download\n",
    "        'IMAGES_STORE': 'DA-images', #store images in DA-images folder\n",
    "        'FEED_FORMAT':'json',                                \n",
    "        'FEED_URI': 'image-data.json', #store image data in image-data.json\n",
    "        'DOWNLOAD_FAIL_ON_DATALOSS': False, #if image download fails (due to various issues), don't send error message, just flag it.\n",
    "        'DOWNLOAD_DELAY': 0.25 #250 ms download delay, with inbuilt scrapy randomization\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        \n",
    "        #get page body\n",
    "        page = response.css('div.page-results span.thumb')\n",
    "        \n",
    "        for img in page:\n",
    "            \n",
    "            #thumbnail link. If there isn't a thumbnail, then post is not an image and should be skipped\n",
    "            thumbnail = img.css('::attr(data-super-img)').get()\n",
    "            \n",
    "            #img_link contains the full link that leads to the individual image post\n",
    "            img_link = img.css('::attr(href)').get()\n",
    "            \n",
    "            #if there is a thumbnail, aka the post is an image, follow url to parse image for details\n",
    "            if thumbnail: \n",
    "                yield scrapy.Request(img_link, callback = self.parse_image)\n",
    "                self.new_items += 1\n",
    "                if (self.new_items - self.old_items) == 100:\n",
    "                    self.old_items = self.new_items\n",
    "                    print(f\"Downloaded {self.new_items} images...\")\n",
    "                \n",
    "        #go to next page\n",
    "        #while self.offset < self.offset_limit:\n",
    "            #self.offset += 24 #DA's natural offset scroll is set at increments of 24\n",
    "            #next_page = f'https://www.deviantart.com/popular-all-time/?q=sherlock&offset={self.offset}'\n",
    "            #yield scrapy.Request(next_page, callback=self.parse)\n",
    "            \n",
    "            \n",
    "    def parse_image(self, response):\n",
    "        \n",
    "        #initialize image item\n",
    "        image = ImageItem()\n",
    "        \n",
    "        #get image url (for downloading via ImagePipeline)\n",
    "        image[\"image_urls\"] = [response.css('div.dev-view-deviation img ::attr(src)').get()]\n",
    "        #get other image info\n",
    "        image['titles'] = response.xpath(\"//a[@class='title']/text()\").extract()[0]\n",
    "        image['date_posted'] = response.xpath(\"//div[@class='dev-right-bar-content dev-metainfo-content dev-metainfo-details']/dl/dd/span/text()\").extract()[0]\n",
    "        \n",
    "        #check whether image has hashtags (some don't)\n",
    "        hashtag = response.xpath(\"//div[@class='dev-about-tags-cc dev-about-breadcrumb']/a/text()\").extract()\n",
    "        if hashtag: image['hashtag'] = hashtag\n",
    "        \n",
    "        #get image stats\n",
    "        stats =  response.xpath(\"//div[@class='dev-right-bar-content dev-metainfo-content dev-metainfo-stats']/dl/dd/text()\").extract()\n",
    "        \n",
    "        #check that stats list only contains numbers (sometimes irregular data falls in)\n",
    "        stats = [re.sub(\"\\D\", \"\", s) for s in stats]\n",
    "        \n",
    "        #remove any None types from list\n",
    "        stats = list(filter(None, stats))\n",
    "        \n",
    "        #the responses are ordered in: views, faves, comments, downloads\n",
    "        #sometimes comments are disabled, sometimes downloads are disabled\n",
    "        headers = ['views','faves','comments','downloads']\n",
    "        \n",
    "        #if comments/downloads are disabled, they will not be looped over for a given image\n",
    "        for i in range(len(stats)):\n",
    "            image[headers[i]] = stats[i]\n",
    "            \n",
    "        #get artist info\n",
    "        artist_name = response.xpath(\"//small[@class='author']/span/a/text()\").extract()\n",
    "        \n",
    "        if artist_name: \n",
    "            image['artists'] = response.xpath(\"//small[@class='author']/span/a/text()\").extract()[-1]\n",
    "            image['artist_urls'] = response.xpath(\"//small[@class='author']/span/a/@href\").extract()[-1]     \n",
    "            request = scrapy.Request(image['artist_urls'], callback=self.parse_artist, meta={'image':image})\n",
    "            yield request\n",
    "        else: #if no artist name (sometimes artists are banned), just yield the image\n",
    "            image['artists'] = 'Banned'\n",
    "            yield image\n",
    "        \n",
    "    def parse_artist(self, response):\n",
    "        \n",
    "        #get image item for the higher-level parser\n",
    "        image = response.meta['image']\n",
    "        \n",
    "        #get artist account stats\n",
    "        artist_stats = response.xpath(\"//div[@id='super-secret-stats']/div/div/div/strong/text()\").extract()\n",
    "        \n",
    "        headers = ['artist_deviations','artist_comments','artist_page_views','artist_scraps','artist_watchers','artist_critiques','artist_forum_posts','artist_faves']\n",
    "        \n",
    "        for i in range(len(artist_stats)):\n",
    "            image[headers[i]] = artist_stats[i]\n",
    "        \n",
    "        #get account age and membership details\n",
    "        age_membership = response.xpath(\"//a[@href='#super-secret-activity']/div/text()\").extract()\n",
    "        \n",
    "        #sometimes the age wrapped up in a span\n",
    "        if len(age_membership) == 0: \n",
    "            age = response.xpath(\"//a[@href='#super-secret-activity']/span/div/text()\").extract()[0]\n",
    "            age_membership.append(age)        \n",
    "        image['account_age'] = age_membership[0]\n",
    "\n",
    "        \n",
    "        #get artist personal details\n",
    "        artist_details = response.xpath(\"//div[@id='super-secret-why']/div/div/div/dl/dd/text()\").extract()\n",
    "        details = ['artist_asl','artist_dob'] #some artists do not share their dobs\n",
    "        for i in range(len(artist_details)):\n",
    "            image[details[i]] = artist_details[i]\n",
    "        \n",
    "        return image\n",
    "            \n",
    "process = CrawlerProcess()\n",
    "process.crawl(ImageSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('image-data.json')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
