{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Final Project: Predicting Fanart Popularity using Social Metrics and Images</h1>\n",
    "\n",
    "<h2>Problem Statement</h2>\n",
    "\n",
    "Predicting image popularity is an interesting and potentially profitable task considering that many users post images on social media platforms to increase social and commercial influence - the more popular the image, the greater the influence (De Veirman, Cauberghe, & Hudders, 2017). Analyzing image popularity also provides insight into the mindset and proclivity of the audience, and prompts us to consider the various factors involved in promoting image popularity. \n",
    "\n",
    "In this project, I aim to use machine learning techniques to predict the popularity of artwork scraped from <a href=\"https://www.deviantart.com/\">DeviantArt.com</a> - specifically fanart for the Sherlock Holmes fandom. Both social metrics and the images themselves will be considered when building the predictive model(s).\n",
    "\n",
    "<h3>Deviantart</h3>\n",
    "\n",
    "Deviantart.com is \"the world's largest online social community for artists and art enthusiasts\" (DeviantArt, 2019). The website was launched on August 7, 2000, and is still up and running with an active community of artists and viewers alike. According to their About page, they have over 44 million registered members and attract over 45 million unique visitors per month. Members upload tens of thousands of original pieces of artwork every day (DeviantArt, 2019).\n",
    "\n",
    "I chose to scrape Deviantart for the data since a large portion of the user-submitted images consist of fanart.\n",
    "\n",
    "<h3>Fanart</h3>\n",
    "\n",
    "Fan art is artwork created by fans of a work of fiction and derived from a series character or other aspect of that work (Wikipedia contributors, 2019). It is an interesting subcategory of art to explore since it is explicitly derived from a specific fictional work - which has its own artistic style - and seeks to replicate, or at least pay tribute to some elements of the original work. \n",
    "\n",
    "<h3>Sherlock Holmes</h3>\n",
    "\n",
    "Sherlock Holmes is a fictional private detective created by British author Sir Arthur Conan Doyle (Wikipedia, 2019). According to the Guinness World Records, Sherlock Holmes has the \"world record for the most portrayed literary human character in film & TV\", having been depicted on screen 254 times (Guinness World Record, 2012). The most recent and arguably most popular adaptations include the 2009 movie adaptation staring Robert Downey Jr. and the 2010 - 2017 BBC One series staring Benedict Cumberbatch.\n",
    "\n",
    "I chose Sherlock Holmes as the target fandom on the basis that it had a large fanbase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Solution Specification</h2>\n",
    "\n",
    "<h3>Features</h3>\n",
    "\n",
    "<h4>Predictors</h4>\n",
    "\n",
    "Prior research on predicting image popularity showed that leveraging both image features as well as social cues allowed the reliable prediction of \"the normalized view count of images with a rank correlation of up to 0.81\" (Khosla, Das Sarma, & Hamid, 2014). \n",
    "\n",
    "Intuitively, we are aware that image popularity cannot be predicated on solely social cues or image aesthetics. It is trivial to see that the more popular the content-creator, the more popular their content will be. As for image aesthetics, Dufour (2014) makes a neat statement in his paper on image popularity prediction: “it’s clear, at least trivially, that [image popularity] cannot be due entirely to exogenous features (i.e., features that are not contingent on the image itself). As proof, we offer the fact that the majority of imagespace is images of noise, yet very few images of noise are widely popular. Furthermore, images that are objectively aesthetic or attractive—either due to composition or content—are plainly more likely to be popular.”\n",
    "\n",
    "\n",
    "The predictors will thus consist of social cues in the form of artist attributes, and image features extracted via deep learning. A detailed breakdown of the extracted features is shown in the Data Importing section.\n",
    "\n",
    "<h4>Response variable</h4>\n",
    "\n",
    "While there are various metrics to consider when judging image popularity (number of views, comments, favorites, downloads, etc.), I will simply be using number of image favorites as a proxy for popularity. In their study, Khosla et al. used number of image views (2014) as a proxy. \n",
    "\n",
    "In future work, one could consider how a mixture of various metrics may lead to the \"best\" popularity measure. \n",
    "\n",
    "<h3>Models</h3>\n",
    "\n",
    "Model will be built to predict image popularity based on either social metrics or image features.\n",
    "\n",
    "<h4>Social Metrics</h4>\n",
    "\n",
    "Four linear regression models are trained as well as a neural network model to compare their performances. The models and their explanations are shown below:\n",
    "\n",
    "<h5>Ordinary Least Squares (OLS) Regression</h5>\n",
    "\n",
    "OLS regression determines parameter values by minimizing the sum of the squared residuals. Since there is no bias introduced through a penalty parameter, OLS regression models can have a large amount of variance. \n",
    "\n",
    "<h5>Ridge Regression</h5>\n",
    "\n",
    "Ridge regression is only known as Penalized Least Squares (PLS) regression. It introduces a small amount of bias into how the line is fit to the data to significantly drop the variance of the model. Ridge regression determines parameter values by minimizing (sum of squared residuals) + (λ x the slope^2) where λ is the regularization parameter and can be determined via cross-validation using sklearn's RidgeCV() function.\n",
    "\n",
    "<h5>Lasso Regression</h5>\n",
    "\n",
    "Similar to ridge regresssion, lasso regression introduces bias into the training procedure by minimizing (sum of squared residuals) + ( λ x  the slope  ). As seen from the minimizing equation, ridge regression can only shrink the slope asymptotically close to 0, while lasso regression can shrink the slope all the way to 0. As such, lasso regression is superior to ridge regression at reducing variance in models that contain a lot of useless variables. λ can be determined via cross-validation using sklearn's LassoCV() function.\n",
    "\n",
    "<h5>Elastic Net Regression</h5>\n",
    "\n",
    "Elastic net regression minimizes the sum of squared residuals + lasso regression penalty + ridge regression penalty. Elastic net regression combines elements of both ridge and lasso by grouping and shrinking the parameters associated with correlated variables, and leaving them in the equation or removing them all at once. The λ's for both the ridge and lasso penalty components can be determined via cross-validation using sklearn's ElasticNetCV() function.\n",
    "\n",
    "<h5>Neural Network</h5>\n",
    "\n",
    "A neural network with a single hidden layer with nonlinear activation functions is considered to be a Universal Function Approximator, i.e. capable of learning any function. Since neural networks are capable of learning highly complex functions, they should perform better if there are many non-linear relationships within the data. \n",
    "\n",
    "    \n",
    "<h4>Image Features</h4>\n",
    "\n",
    "A convolutional neural network (CNN) is trained to predict image popularity based on image features.\n",
    "\n",
    "The CNN will be an adaptation of the VGG16 model designed by Simonyan and Zisserman (2014). Distinctive features of the VGG16 model include  very deep convolutional layers (up to 19 weight layers) and small convolution filters (3 x 3), which allowed the model to achieve 92.7% top-5 test accuracy in ImageNet Large Scale Visual Recognition Competition (ILSVRC), thus allowing the authors to conclude that \"representation depth is beneficial for the classification accuracy\" (Simonyan & Zisserman, 2014). \n",
    "\n",
    "The model also generalises well to a wide range of tasks and datasets. The authors tested the model on a variety of classification tasks outside of ImageNet (which mostly consisted of 10K + images with labels) and found consistent average precision (AP) scores of ~89%. \n",
    "\n",
    "Since Khosla et al. (2014) built on Krizhevsky, Sutskever, and Hinton's CNN model (which has about 1 - 5 weight layers) to predict image popularity, and VGG16 has outperformed their original CNN model in various ILSVRC competitions, it would appear to be a good choice to adapt the VGG16 model for my own use in predicting image popularity.\n",
    "\n",
    "The downside of using VGG16 is that it takes a long time to train (Hassan, 2018), which makes sense considering the deep convolutional layer architecture. Due to time constraints, I will only be training the model for 50 epochs with a batch size of 30 images. It should also be noted that the original model was trained for image classification, while I am using it for a regression problem. Furthermore, the model was meant to be used on real-life images, while I am using it on fanart, which can be life-like or cartoonish in nature depending on the artist's style.\n",
    "\n",
    "Since the CNN mostly operates as a black-box, i.e. the predictive power of the image features as calculated by the CNN are hard to interpret, in future work I could implement techniques of extracting high-level image featues as well such as color intensity, color hue, color contrast, etc. as performed by Khosla et al. (2014)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Collection</h2>\n",
    "\n",
    "To gather the data, I scraped Deviantart for images categorized under the 'sherlock' search query. The exact url used was: https://www.deviantart.com/popular-all-time/?q=sherlock&offset=0. The images were supposingly ordered according to \"popular of all time\", but I found a mix of both popular and not-so-popular images within my sample size of 5638 images out of the ~190,000 results available. Alongside the images themselves, social metrics in the form of views, downloads, favorites, and various artist attributes were also scraped from the image and artist pages. \n",
    "\n",
    "The web-scraped was built using a free and open-source Python web-scraping framework, <a href=\"https://scrapy.org/\">scrapy</a>. I scraped only image posts, and made sure to avoid scraping posts of other formats, e.g. literature. I set a download delay of 250 ms - which had inbuilt scrapy randomization applied to it - as a form of web-scraping etiquette by not downloading a bulk of images continuously, and also to avoid my web-scraper's behavior being obviously detectable as non-human (just in case). \n",
    "\n",
    "The reiteration process to fix bugs took time, and my scraper also crashed even on a few bug-free runs, so I settled on downloading 5638 images for now. The scraped images were stored in my local drive under the folder, 'DA-images-2'. The image data was stored in a json file, 'image-data-2'.\n",
    "\n",
    "\n",
    "A full breakdown of the scraped data can be found below in the Data Importing section.\n",
    "\n",
    "The web-scraper code can be found in the Appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Importing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1) #for displaying the full image urls so that they are clickable (if needed)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('image-data-2.json')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data explanation and observations\n",
    "explanation_df = pd.DataFrame({\n",
    "    'Columns':df.columns,\n",
    "    'Description':[\n",
    "        \"Artist's account age\",\n",
    "        \"Artist's age/sex/location\",\n",
    "        \"Total number of comments recieved by artist\",\n",
    "        \"Total number of critiques given by artist (Critique is designed to be a thorough evaluation of a deviation on a number of different qualities)\",\n",
    "        \"Artist's Number of posts\",\n",
    "        \"Artist's Date of Birth\",\n",
    "        \"Total number of favorites received by artist\",\n",
    "        \"Total number of forum posts made by artist\",\n",
    "        \"Total number of page views received by artist\",\n",
    "        \"Total number of scraps made by artist (Scraps are Works in Progress or Archieved Work)\",\n",
    "        \"Link to the artist's account page\",\n",
    "        \"Artist's number of watchers (followers)\",\n",
    "        \"Artist's username\",\n",
    "        \"Number of image comments\",\n",
    "        \"The date the image was posted\",\n",
    "        \"Number of image downloads\",\n",
    "        \"Number of image favorites\",\n",
    "        \"Number of image hashtags\",\n",
    "        \"Link to the full image page\",\n",
    "        \"Image path in local storage\",\n",
    "        \"Link to image download\",\n",
    "        \"Image title\",\n",
    "        \"Number of image views\"    \n",
    "    ],\n",
    "    'Missing Value Count':[\n",
    "        df[i].isna().sum() for i in df.columns\n",
    "    ],\n",
    "    'Reason for Missing Values':[\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some artist's keep their Date of Birth hidden\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"Some images have banned artists, so the artist's account does not exist\",\n",
    "        \"NA\",\n",
    "        \"Some images have comments disabled\",\n",
    "        \"NA\",\n",
    "        \"Some images have the download function disabled\",\n",
    "        \"Oddity - image itself was not downloaded but artist was\",\n",
    "        \"Some images don't have hashtags\",\n",
    "        \"NA\",\n",
    "        \"NA\",\n",
    "        \"NA\",\n",
    "        \"NA\",\n",
    "        \"Oddity - image itself was not downloaded but artist was\" \n",
    "    ],\n",
    "})\n",
    "\n",
    "explanation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Cleaning and Preprocessing</h2>\n",
    "\n",
    "The dataframe info reveals that some of the columns are not in the right format, and there are also some missing values. Most - if not all - of the missing values can be rationally explained, as shown in the table above. While I would ideally have cleaned all the columns, some of the columns required non-trivial cleaning methods, and so I omitted cleaning them due to time constraints. Given additional time and resources, I believe that the \"ignored\" columns should be cleaned as they could potentially provide significant predictive power to the model, bearing in mind that those with a significant number of missing values may skew the model if an appropriate filtering method is not chosen.\n",
    "\n",
    "The following section details the cleaning process of all the \"cleaned\" columns, and the section below this lists the \"ignored\" columns as well as brief explanations as to why their cleaning process would be non-trivial. In some cases, the portion of non-null objects is too small to justify cleaning the column, e.g. <b>hashtags</b> only has 653 data points out of 5638 within the entire dataset.\n",
    "\n",
    "<h3>Cleaned Columns</h3>\n",
    "\n",
    "Cleaned columns are columns that were <b>included in the cleaning process.</b> This means that the columns fit the following criteria:\n",
    "\n",
    "a) need to be cleaned due to improper format; \n",
    "\n",
    "b) have strong justification for being cleaned (sufficient data points, cleaning process does not take too long, etc.). \n",
    "\n",
    "Do note that columns which need not be cleaned may still be included in the final dataframe to be analyzed, even if they are not listed below.\n",
    "\n",
    "<b>Cleaned columns:</b>\n",
    "\n",
    "- account_age           \n",
    "- artist_comments            \n",
    "- artist_deviations     \n",
    "- artist_faves          \n",
    "- artist_forum_posts    \n",
    "- artist_page_views     \n",
    "- artist_scraps                 \n",
    "- artist_watchers                   \n",
    "- date_posted                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Account Age</h3>\n",
    "\n",
    "The account age column is cleaned from a string format of \"Deviant for -- Years/Months\" to be the time delta of the account age in days. There are 17 NaN values leftover after the cleaning process since there are 17 banned artists, aka artists whose accounts have been disabled, and so do not have a valid artist_url to extract data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning account_age column\n",
    "print(\"Original calue counts in account_age column\")\n",
    "print(df['account_age'].value_counts(dropna=False))\n",
    "\n",
    "#use test_df first since cleaning process is a bit tricky - avoid overwriting original df\n",
    "test_df = pd.DataFrame() \n",
    "\n",
    "test_df['aa'] = df['account_age'].replace(r'^\\s*$', np.nan, regex=True) #replace empty spaces with nan\n",
    "test_df['value'] = test_df['aa'].str.extract('(\\d+)').astype(float) #extract time value\n",
    "test_df['time_unit'] = test_df['aa'].str[-6:] #extract time unit\n",
    "test_df['time_unit'] = test_df['time_unit'].str.strip() #strip time unit of any blank spaces\n",
    "\n",
    "#if time unit is months, convert value to month time delta, else convert to year time delta\n",
    "test_df['value'] = np.where(test_df['time_unit']=='Months', \n",
    "                            pd.to_timedelta(test_df['value'], unit='M'),\n",
    "                             pd.to_timedelta(test_df['value'], unit='Y'))\n",
    "\n",
    "print()\n",
    "print(\"Cleaned value counts\")\n",
    "print(test_df['value'].value_counts(dropna=False).sort_values(ascending=False))\n",
    "\n",
    "#lastly, assign cleaned column back to original df\n",
    "df['account_age'] = test_df['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Date posted</h3>\n",
    "\n",
    "The date posted column is cleaned by converting it from string to a datetime object. A new column, \"image_age\" is created by taking the difference between the date of the latest image posted in the dataset and the image's own posted date. This means that older images will have larger image_age values, while newer images will have smaller image_age values, with the newest image having an image_age of 0.\n",
    "\n",
    "The image_age unit is in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning date_posted column by converting dates to datetime\n",
    "#a few dates don't have years, which makes their \"age\" quite meaningless. \n",
    "#The errors are coerced so produce NaN outputs, which will later be removed from the dataset.\n",
    "test_df['date_posted'] = pd.to_datetime(df['date_posted'], errors='coerce') \n",
    "\n",
    "#get number of days between image post date and newest post date in dataset\n",
    "test_df['image_age'] = (test_df['date_posted'].max() - test_df['date_posted']).dt.days\n",
    "print(f\"Newest date in dataset: {test_df['date_posted'].max()}\")\n",
    "print(f\"Number of Nans: {sum(test_df['image_age'].isna())}\")\n",
    "\n",
    "#assign image_age and date_posted column to actual df\n",
    "df['image_age'] = test_df['image_age']\n",
    "df['date_posted'] = test_df['date_posted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning artist attributes - done in bulk because trivial\n",
    "df['artist_comments'] = df['artist_comments'].str.replace(',', '').astype(float)\n",
    "df['artist_deviations'] = df['artist_deviations'].str.replace(',', '').astype(float)\n",
    "df['artist_faves'] = df['artist_faves'].str.replace(',', '').astype(float)\n",
    "df['artist_forum_posts'] = df['artist_forum_posts'].str.replace(',', '').astype(float)\n",
    "df['artist_page_views'] = df['artist_page_views'].str.replace(',', '').astype(float)\n",
    "df['artist_scraps'] = df['artist_scraps'].str.replace(',', '').astype(float)\n",
    "df['artist_watchers'] = df['artist_watchers'].str.replace(',', '').astype(float)\n",
    "\n",
    "print('Artist attributes cleaned.')\n",
    "\n",
    "#clean image_paths and image_urls by extracting the string from list\n",
    "df['image_paths'] = df['image_paths'].str[0]\n",
    "df['image_urls'] = df['image_urls'].str[0]\n",
    "\n",
    "print('Image path and url cleaned.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ignored columns</h3>\n",
    "\n",
    "Ignored columns are columns that were omitted from the cleaning process despite needing to be cleaned, usually because the cleaning process is too time-consuming (or beyond my skill-level), or the column has too few data points. There are some columns that will be ultimately ignored in the final process, but are not listed here since the data was in the right format (aka they do not need to be cleaned).\n",
    "\n",
    "<h4>'artist_asl'</h4> \n",
    "\n",
    "Data type: List of the age, gender, and country of the artist. \n",
    "\n",
    "This is a non-trivial cleaning process since artists may choose to list none to all of the categories listed above, and so trying to parse the list order and assign elements to the proper categories of age, gender, and country can get confusing. Some of the values are also 'Unknown'.\n",
    "\n",
    "<h4>'artist_dob'</h4>\n",
    "\n",
    "Data type: A string of the artist's date of birth.\n",
    "\n",
    "The column was ignored for two reasons. First, there are only 2678 non-null entries. Second, a good amount of entries do not contain a year within the birthdate, which one would assume to have the most potential significant influence.\n",
    "\n",
    "<h4>'hashtags'</h4>\n",
    "\n",
    "Data type: List of hashtags posted with the image entry.\n",
    "\n",
    "The column has only 408 non-null entries, and so was rejected. That being said, it would be interesting in the future to use natural language processing techniques to identify patterns in hashtags within a particular fandom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dropna to demonstrate the ignore columns data formats\n",
    "df[['artist_asl','artist_dob','hashtags']].dropna().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Final Dataframe</h3>\n",
    "\n",
    "In the final iteration of dataframe cleaning, the 'Ignored' columns were removed. The 'downloads' was also removed since it only has 2493 non-null data points. \n",
    "\n",
    "'faves' is intended as the predicted variable. Although some of the columns such as 'comments' and 'views' can't fairly be used in the predictive process (since one does not know the number of views and comments of an image beforehand), they are still retained for analysis of their distributions and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final df\n",
    "final_df = df[['account_age','artist_comments','artist_critiques','artist_deviations','artist_faves',\n",
    "              'artist_forum_posts', 'artist_page_views', 'artist_scraps', 'artist_watchers', 'artists',\n",
    "              'comments', 'faves', 'titles', 'views', 'date_posted','image_age',\n",
    "              'image_links','image_paths','image_urls','artist_urls']]\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Nans in DataFrame:\\n\\n{final_df.isna().sum()}\")\n",
    "\n",
    "#fill all NaN values with the column's mean amount\n",
    "final_df = final_df.fillna(final_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final Number of Nans in DataFrame after filling missing values with column mean:\\n\\n{final_df.isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Analysis</h2>\n",
    "\n",
    "All the data has been cleaned, there are only 6 NaN values in the date_posted and artist_urls columns, but this can be ignored because:\n",
    "\n",
    "- <b>'date_posted':</b> The mean can't be applied to the NaN values since there can't be a \"mean\" date. Furthermore, 'date_posted' will not be used in the regression analysis so the 6 NaNs can be safely left in.\n",
    "\n",
    "\n",
    "- <b>'artist_urls':</b> The 9 banned artist do not have artist urls so the NaN values remain. The artist_url will also not be used in the regression.\n",
    "\n",
    "The following analyses wil be conducted to get a better understanding of the data that is being handled:\n",
    "\n",
    "- Analyzing descriptive statistics (mean, max, mode, unique values, etc.)\n",
    "\n",
    "\n",
    "- Analyzing the distributions and correlations in the data (using a pairplot)\n",
    "\n",
    "\n",
    "- Analyzing any variables which contain a time-series component. In this case, only date_posted has a time-series component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Descriptive Statistics</h3>\n",
    "\n",
    "From the descriptive statistics tables below, we see that \n",
    "\n",
    " - lots of zeros in critiques, forum posts, and scraps - most deviantart users don't use these functionalities much. As someone who used to use DeviantArt, I can attest to that.\n",
    " \n",
    " - include max, min, and some links? Qualitative analysis - most popular artists and least popular artists.\n",
    " \n",
    " - 17 banned artists, as expected.\n",
    " \n",
    " - unique title and artists...wanted to use length or something but decided that it probably won't have significant impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Distributions and Correlations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors are features that the artist knows before posting an image (faves is also included as the response variable)\n",
    "predictors = ['artist_comments','artist_critiques','artist_deviations','artist_faves','artist_forum_posts',\n",
    "            'artist_page_views','artist_scraps','artist_watchers','faves']\n",
    "\n",
    "sns.pairplot(final_df[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_predictors_df = np.log(final_df[predictors] + 1)\n",
    "\n",
    "sns.pairplot(log_predictors_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = log_predictors_df.corr()\n",
    "plt.figure(figsize = (10,6), dpi=200)\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,\n",
    "            annot=True, annot_kws={\"size\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these other features are only known after posting\n",
    "others = ['comments','views','faves','image_age']\n",
    "sns.pairplot(final_df[others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only log comments, faves, and views since image_age is already normally distributed\n",
    "log_others_df = np.log(final_df[['comments','views','faves']] + 1)\n",
    "log_others_df = pd.concat([log_others_df, final_df['image_age']], axis = 1)\n",
    "sns.pairplot(log_others_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = log_others_df.corr()\n",
    "plt.figure(figsize = (3,2.5), dpi=150)\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,\n",
    "            annot=True, annot_kws={\"size\": 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Time-series of Date Posted</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month-year column to get monthly time periods\n",
    "final_df['month_posted'] = final_df['date_posted'].dt.month\n",
    "final_df['year_posted'] = final_df['date_posted'].dt.year\n",
    "final_df['month_year_posted'] = final_df['date_posted'].dt.to_period('M')\n",
    "\n",
    "def create_time_series(timescale, title, label_size=14, title_size=15, x_tick_size=13, side_plots = True):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        timescale (str): name of timescale column to be used in groupby function \n",
    "                         to get average faves per post and number of posts \n",
    "                         \n",
    "        title (str): name of timescale to appear in the title and x-axis label\n",
    "        \n",
    "        label_size (int): x-axis and y-axis font size. Default: 13\n",
    "        \n",
    "        title_size (int): title font size. Default: 15\n",
    "        \n",
    "        x_tick_size (int): x-ticks font size. Default: 13\n",
    "        \n",
    "        side_plots (bool): if True, plots will be displayed side by side.\n",
    "                            If False, plots will be displayed top and bottom.\n",
    "                            Default: True\n",
    "        \n",
    "    Outputs:\n",
    "        Two bar plots showing the average number of faves and number of posts\n",
    "        over the given timescale.\n",
    "    '''\n",
    "    if side_plots:\n",
    "        a = 221\n",
    "        b = 222\n",
    "    else:\n",
    "        a = 211\n",
    "        b = 212\n",
    "    \n",
    "    #make df of average faves and number of posts over timescale\n",
    "    avg_faves = final_df.groupby(final_df[timescale]).mean()\n",
    "    no_of_posts = final_df.groupby(final_df[timescale]).count()\n",
    "    \n",
    "    #plot the dfs\n",
    "    plt.subplot(a)\n",
    "    avg_faves['faves'].plot(kind='bar')\n",
    "    plt.title(f\"Average Number of Faves per {title}\", fontsize=title_size)\n",
    "    plt.xlabel(f\"{title}\", fontsize=label_size)\n",
    "    plt.xticks(fontsize=x_tick_size, rotation=90)\n",
    "    plt.ylabel(\"Average number of faves\", fontsize=label_size)\n",
    "\n",
    "    plt.subplot(b)\n",
    "    no_of_posts['faves'].plot(kind='bar')\n",
    "    plt.title(f\"Average Number of Posts per {title}\", fontsize=title_size)\n",
    "    plt.xlabel(f\"{title}\", fontsize=label_size)\n",
    "    plt.xticks(fontsize=x_tick_size, rotation=90)\n",
    "    plt.ylabel(\"Average number of posts\", fontsize=label_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15), dpi=200)\n",
    "create_time_series('month_posted', 'Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15), dpi=200)\n",
    "create_time_series('year_posted', 'Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,25), dpi=300)\n",
    "create_time_series('month_year_posted', 'Month-Year', label_size=20, title_size=27, x_tick_size=11, side_plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "#find the outlier\n",
    "outlier_date = datetime.strptime('2008-10','%Y-%m')\n",
    "outlier_df = final_df[['faves','artists','titles','image_paths','image_links']].loc[np.where((\n",
    "    final_df['year_posted'] == outlier_date.year) & (final_df['month_posted'] == outlier_date.month))]\n",
    "display(HTML(outlier_df.to_html()))\n",
    "\n",
    "print(outlier_df['image_links'])\n",
    "img = mpimg.imread('DA-images/'+ 'full/cf5fd090c1f8cb96bef89b500abb6974e66cb600.jpg')\n",
    "plt.imshow(img)\n",
    "plt.grid(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model-Building</h2>\n",
    "\n",
    "- Explain the use of the different linear models. What is linear, ridge, and lasso?\n",
    "\n",
    "- Compare performance in logged vs unlogged models?\n",
    "- If you want to compare the log transform model vs the normal model, then you can also look at exponentiating your predictions, and compare the mean errors. Maybe look at a residual plot for both models in log space? \n",
    "\n",
    "\n",
    "<h3>Features selection</h3>\n",
    "\n",
    "Interestingly, feature selection shows that all the features are important for model performance (Rank 1). This is especially interesting considering that when I did this earlier with a smaller sample size (3000 points), at least one or two features would get dropped. This suggests that as more data is collected, the predictive power of the social metrics becomes more apparent and influential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear models for social metric prediction\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV #recursive feature elimination with cross-validation\n",
    "\n",
    "X_log = log_predictors_df.drop('faves',1)\n",
    "X = final_df[predictors].drop('faves',1) #for comparison later\n",
    "\n",
    "y = log_predictors_df['faves']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y, test_size=0.2, random_state = 10)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector_model(estimator, X_train, y_train): \n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train (arr): Feature array of data.\n",
    "        y_train (arr): Response array of data.\n",
    "        \n",
    "    Outputs:\n",
    "        selector: estimator with feature selection applied\n",
    "        \n",
    "    Attributes:\n",
    "        ranking_: The feature ranking, such that ranking_[i] corresponds to the ranking position \n",
    "                    of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1.\n",
    "    '''\n",
    "    \n",
    "    selector = RFECV(estimator, step = 1, scoring='neg_mean_squared_error').fit(X_train, y_train)\n",
    "    return selector\n",
    "\n",
    "def align_coefficients(selector):\n",
    "    '''\n",
    "    Simple function to adjust coefficient layout in dataframe to correspond with \n",
    "    selected features from the given selector.\n",
    "    '''\n",
    "    coefs = []\n",
    "    j = 0\n",
    "    for i in range(len(selector.ranking_)):\n",
    "        if selector.ranking_[i] != 1: \n",
    "            coefs.append(np.nan)\n",
    "        else:\n",
    "            coefs.append(selector.estimator_.coef_[j])\n",
    "            j += 1\n",
    "    return coefs\n",
    "\n",
    "linear_reg = selector_model(LinearRegression(), X_train, y_train)\n",
    "ridge_reg = selector_model(RidgeCV(), X_train, y_train)\n",
    "lasso_reg = selector_model(LassoCV(), X_train, y_train)\n",
    "\n",
    "feature_df = pd.DataFrame({\"Features\":X_log.columns,\n",
    "                           \"Linear Regression Feature Ranking\": linear_reg.ranking_,\n",
    "                           \"Linear Regression Coefficients\": align_coefficients(linear_reg),\n",
    "                           \"Ridge Regression Feature Ranking\": ridge_reg.ranking_,\n",
    "                           \"Ridge Regression Coefficients\": align_coefficients(ridge_reg),\n",
    "                           \"Lasso Regression Feature Ranking\": lasso_reg.ranking_,\n",
    "                           \"Lasso Regression Coefficients\": align_coefficients(lasso_reg)})\n",
    "\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "def create_mlp(dim):\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = create_mlp(X_train.shape[1])\n",
    "nn_model.compile(loss=\"mse\", optimizer='adam', metrics=['mae','mse','mape'])\n",
    "nn_model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split = 0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6),dpi=200)\n",
    "plt.plot(nn_model.history.history['loss'], label='loss')\n",
    "plt.plot(nn_model.history.history['val_loss'], label='val_loss')\n",
    "plt.title(\"Neural Network Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "def predict_score(model, X_test, y_test):\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    expl_var = explained_variance_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mede = median_absolute_error(y_test, predictions)\n",
    "    scores = [r2, expl_var, mse, mae, mede]\n",
    "    \n",
    "    return predictions, scores\n",
    "\n",
    "lin_pred, lin_score = predict_score(linear_reg, X_test, y_test)\n",
    "ridge_pred, ridge_score = predict_score(ridge_reg, X_test, y_test)\n",
    "lasso_pred, lasso_score = predict_score(lasso_reg, X_test, y_test)\n",
    "nn_pred, nn_score = predict_score(nn_model, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_row(index):\n",
    "    return [lin_score[index],ridge_score[index],lasso_score[index],nn_score[index]]\n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "            {\"Algorithm\": [\"Linear Regression\",\"Ridge Regression\",\"Lasso Regression\", \"Neural Network Regression\"],\n",
    "            \"r2 score\": create_table_row(0),\n",
    "            \"Explained variance score\":create_table_row(1),\n",
    "             \"Mean Squared Error\": create_table_row(2),\n",
    "            \"Mean Absolute Error\": create_table_row(3),\n",
    "             \"Median Absolute Error\": create_table_row(4)\n",
    "            })\n",
    "scores_df.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "\n",
    "K = range(1,16)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k).fit(log_predictors_df.drop('faves',1))\n",
    "    sum_of_squared_distances.append(km.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6), dpi=120)\n",
    "plt.plot(K, sum_of_squared_distances)\n",
    "plt.title(\"Elbow plot of Sum of Squared Distance vs \\nNumber of Clusters\", size=12)\n",
    "plt.xlabel(\"Number of Clusters (K)\", size=10)\n",
    "plt.ylabel(\"Sum of squared distance\", size=10)\n",
    "plt.show()\n",
    "\n",
    "kmeans = KMeans(n_clusters=3).fit(log_predictors_df.drop('faves',1))\n",
    "cluster_df = pd.DataFrame(kmeans.cluster_centers_).round(2)\n",
    "cluster_df.columns = predictors[:-1] #remove 'faves'\n",
    "cluster_df.reset_index(level=0, inplace=True)\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10), dpi=200)\n",
    "pd.plotting.parallel_coordinates(cluster_df, \"index\", colormap='viridis')\n",
    "plt.title(\"Parallel Coordinates Plot of \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN time</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "#create empty image lists\n",
    "image_resized_lst = []\n",
    "image_original_lst = []\n",
    "\n",
    "#height and width of resized image\n",
    "new_height = 250\n",
    "new_width = 250\n",
    "\n",
    "#image loading has to be done one-by-one to ensure that the images are loaded in the corresponding order to the\n",
    "#data collected in the dataframe\n",
    "for i in range(len(final_df)):\n",
    "    my_dir = 'DA-images-2/'\n",
    "    img_path = final_df['image_paths'][i]\n",
    "    #load image\n",
    "    img = mpimg.imread(my_dir + img_path)\n",
    "    image_original_lst.append(img)\n",
    "    #resize image\n",
    "    img_resized = resize(img,(new_height,new_width),\n",
    "                        mode='constant', anti_aliasing=True, anti_aliasing_sigma=None)\n",
    "    image_resized_lst.append(img_resized)\n",
    "    \n",
    "original_arr = np.array(image_original_lst)\n",
    "resized_arr = np.array(image_resized_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original images array shape: {original_arr.shape}\\nResized images array shape: {resized_arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak at the resized images vs original images\n",
    "fig, ax = plt.subplots(2, 6, figsize=(20, 10), dpi=120,\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(6):\n",
    "    ax[0, i].imshow(original_arr[i])\n",
    "    ax[1, i].imshow(resized_arr[i])\n",
    "    ax[0, i].set_title(f\"Faves: {final_df.faves[i]}\", size=15)\n",
    "    \n",
    "ax[0, 0].set_ylabel('Images Original',size=15)\n",
    "ax[1, 0].set_ylabel('Images Resized',size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "vgg16 = VGG16(weights='imagenet',\n",
    "              input_shape=(250, 250, 3),\n",
    "              include_top = False)\n",
    "vgg16.summary()\n",
    "\n",
    "#freeze the lower level layers\n",
    "vgg16.trainable = False\n",
    "\n",
    "#Add the fully-connected layers \n",
    "vgg16_adapted = Sequential()\n",
    "vgg16_adapted.add(vgg16)\n",
    "vgg16_adapted.add(Flatten(name='flatten'))\n",
    "vgg16_adapted.add(Dense(100, activation='relu', name='fc1'))\n",
    "vgg16_adapted.add(Dense(32, activation='relu', name='fc2'))\n",
    "vgg16_adapted.add(Dense(1, activation='linear'))\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "vgg16_adapted.summary()\n",
    "\n",
    "#compile model\n",
    "vgg16_adapted.compile(loss='mse', optimizer='adam', metrics=['mse','mae','mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn_X = resized_arr\n",
    "y = np.array(log_predictors_df['faves'])\n",
    "cnn_X_train, cnn_X_test, y_train, y_test = train_test_split(cnn_X, y, test_size=0.3)\n",
    "\n",
    "print(cnn_X_train.shape,cnn_X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the adapted vgg16 model\n",
    "vgg16_adapted.fit(cnn_X_train, y_train,\n",
    "                  batch_size=30,\n",
    "                  epochs=50,\n",
    "                  validation_split=0.2,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6),dpi=200)\n",
    "plt.plot(vgg16_adapted.history.history['mean_squared_error'], label='mse')\n",
    "plt.plot(vgg16_adapted.history.history['val_mean_squared_error'], label='val_mse')\n",
    "plt.title(\"Adapted VGG16 Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_adapted_score = vgg16_adapted.evaluate(X_test[:100], y_test[:100], verbose=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_results = pd.DataFrame({\n",
    "    'Metrics':vgg16_adapted.metrics_names,\n",
    "    'Scores':vgg16_adapted_score\n",
    "})\n",
    "\n",
    "cnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_exp = np.exp(y_train)\n",
    "prediction = vgg16_adapted.predict(X_train)\n",
    "prediction_exp = np.exp(prediction)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Real Faves: {np.floor(y_train_exp[i])}, \\nPredicted Faves: {np.floor(prediction_exp[i])}\")\n",
    "    plt.imshow(X_train[i])\n",
    "    \n",
    "print(f\"Explained variance score: {explained_variance_score(y_train_exp, prediction_exp)}\")\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_train_exp, prediction_exp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = estimator.predict(X_test)\n",
    "prediction = np.exp(prediction)\n",
    "y_test = np.exp(y_test)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Real Faves: {y_test[i]}, \\nPredicted Faves: {np.floor(prediction[i])}\")\n",
    "    plt.imshow(X_test[i])\n",
    "    \n",
    "print(f\"Explained variance score: {explained_variance_score(y_test, prediction)}\")\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: most of the images were already white bg to begin with so....\n",
    "\n",
    "Ideas to improve the model:\n",
    "- only select pics of a certain dimension? e.g. filter out pics that are too long or too tall.\n",
    "- other color components!! High-level features!!\n",
    "- Normalize for account age (though the direction is unclear). According to Khosla et al. \"visual media tends to receive views over some period of time. To normalize for this effect, we divide the number of views by the duration since the upload date of the given image.\" But from my analysis, it appears that the image age and number of views has a negative correlation, which also makes sense when one considers that older images get buried while newer images are fresh and seen. So a more thorough analysis will have to be done to consider how the normalization should take place. \n",
    "- use a more nuanced \"popularity indicator\" instead of just taking the faves.\n",
    "- more images. lol.\n",
    "- image augmentation\n",
    "\n",
    "Possible extension:\n",
    "- analyze the different types of comments of the image\n",
    "- analyze the title types\n",
    "- analyze the hashtags\n",
    "- analyze description (I avoided it this time cuz there was too much to parse. Artist's put a lot of different elements in their description, e.g. links to other artists, images, emojis and icons.\n",
    "\n",
    "(these are all tricky becuz artist's tend to keep them hidden, but even working with what few artist's keep it open could be interesting)\n",
    "- analyze age, sex, location\n",
    "- analyze artist's activity, e.g. how often they post \n",
    "\n",
    "Ultimate extension:\n",
    "- Compare between different fandoms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>References</b>\n",
    "\n",
    "De Veirman, M., Cauberghe, V., & Hudders, L. (2017). Marketing through Instagram influencers: the impact of number of followers and product divergence on brand attitude. International Journal of Advertising, 36(5), 798-828.\n",
    "\n",
    "DeviantArt. (2019). Copyright Policy. Retrieved March 16, 2019, from https://about.deviantart.com/policy/copyright/\n",
    "\n",
    "Guinness World Record. (2012, May 14). Sherlock Holmes awarded title for most portrayed literary human character in film & TV. Retrieved April 21, 2019, from http://www.guinnessworldrecords.com/news/2012/5/sherlock-holmes-awarded-title-for-most-portrayed-literary-human-character-in-film-tv-41743/\n",
    "\n",
    "Hassan, M. U. (2018, November 21). VGG16 - Convolutional Network for Classification and Detection. Retrieved April 21, 2019, from https://neurohive.io/en/popular-networks/vgg16/\n",
    "\n",
    "Khosla, A., Das Sarma, A., & Hamid, R. (2014, April). What makes an image popular?. In Proceedings of the 23rd international conference on World wide web (pp. 867-876). ACM.\n",
    "\n",
    "Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105).\n",
    "\n",
    "Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n",
    "\n",
    "Wikipedia contributors. (2019, April 13). Fan art. In Wikipedia, The Free Encyclopedia. Retrieved 03:11, April 21, 2019, from https://en.wikipedia.org/w/index.php?title=Fan_art&oldid=892258552\n",
    "\n",
    "Wikipedia contributors. (2019, April 20). Sherlock Holmes. In Wikipedia, The Free Encyclopedia. Retrieved 16:10, April 21, 2019, from https://en.wikipedia.org/w/index.php?title=Sherlock_Holmes&oldid=893342542\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
